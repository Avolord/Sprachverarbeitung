{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1842,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 8.000000000000001e-07,
      "loss": 8.119,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 7.8546,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 2.7e-06,
      "loss": 7.5345,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.6e-06,
      "loss": 7.0764,
      "step": 40
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.6e-06,
      "loss": 6.9819,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.600000000000001e-06,
      "loss": 6.6419,
      "step": 60
    },
    {
      "epoch": 0.04,
      "learning_rate": 6.6e-06,
      "loss": 6.5801,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.6e-06,
      "loss": 6.343,
      "step": 80
    },
    {
      "epoch": 0.05,
      "learning_rate": 8.599999999999999e-06,
      "loss": 6.4118,
      "step": 90
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.600000000000001e-06,
      "loss": 5.9286,
      "step": 100
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.06e-05,
      "loss": 6.0809,
      "step": 110
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.16e-05,
      "loss": 5.9465,
      "step": 120
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 5.9024,
      "step": 130
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 5.9309,
      "step": 140
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 5.8117,
      "step": 150
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.56e-05,
      "loss": 5.8397,
      "step": 160
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.66e-05,
      "loss": 5.4869,
      "step": 170
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.76e-05,
      "loss": 5.7044,
      "step": 180
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.86e-05,
      "loss": 5.3715,
      "step": 190
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 5.2777,
      "step": 200
    },
    {
      "epoch": 0.11,
      "learning_rate": 2.06e-05,
      "loss": 5.4507,
      "step": 210
    },
    {
      "epoch": 0.12,
      "learning_rate": 2.16e-05,
      "loss": 5.4575,
      "step": 220
    },
    {
      "epoch": 0.12,
      "learning_rate": 2.26e-05,
      "loss": 5.5568,
      "step": 230
    },
    {
      "epoch": 0.13,
      "learning_rate": 2.36e-05,
      "loss": 5.5102,
      "step": 240
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.46e-05,
      "loss": 5.4285,
      "step": 250
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 5.3713,
      "step": 260
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 5.316,
      "step": 270
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 5.072,
      "step": 280
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.86e-05,
      "loss": 5.261,
      "step": 290
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.96e-05,
      "loss": 5.2303,
      "step": 300
    },
    {
      "epoch": 0.17,
      "learning_rate": 3.06e-05,
      "loss": 5.1537,
      "step": 310
    },
    {
      "epoch": 0.17,
      "learning_rate": 3.16e-05,
      "loss": 5.0037,
      "step": 320
    },
    {
      "epoch": 0.18,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 5.0097,
      "step": 330
    },
    {
      "epoch": 0.18,
      "learning_rate": 3.35e-05,
      "loss": 5.219,
      "step": 340
    },
    {
      "epoch": 0.19,
      "learning_rate": 3.45e-05,
      "loss": 4.8882,
      "step": 350
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.55e-05,
      "loss": 4.8355,
      "step": 360
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.65e-05,
      "loss": 5.1169,
      "step": 370
    },
    {
      "epoch": 0.21,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 4.9792,
      "step": 380
    },
    {
      "epoch": 0.21,
      "learning_rate": 3.85e-05,
      "loss": 5.0411,
      "step": 390
    },
    {
      "epoch": 0.22,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 5.0583,
      "step": 400
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.05e-05,
      "loss": 5.1129,
      "step": 410
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.14e-05,
      "loss": 5.0297,
      "step": 420
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.24e-05,
      "loss": 4.9043,
      "step": 430
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 4.8912,
      "step": 440
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.44e-05,
      "loss": 4.911,
      "step": 450
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 4.887,
      "step": 460
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.64e-05,
      "loss": 4.9224,
      "step": 470
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.74e-05,
      "loss": 4.6201,
      "step": 480
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 4.7782,
      "step": 490
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.94e-05,
      "loss": 4.5566,
      "step": 500
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.996020692399523e-05,
      "loss": 4.7078,
      "step": 510
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.986072423398329e-05,
      "loss": 4.788,
      "step": 520
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.976124154397135e-05,
      "loss": 4.7221,
      "step": 530
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.966175885395941e-05,
      "loss": 4.5768,
      "step": 540
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.9562276163947475e-05,
      "loss": 4.7124,
      "step": 550
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.946279347393554e-05,
      "loss": 4.7611,
      "step": 560
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.93633107839236e-05,
      "loss": 4.4462,
      "step": 570
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.9263828093911665e-05,
      "loss": 4.6696,
      "step": 580
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.916434540389973e-05,
      "loss": 4.5131,
      "step": 590
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.9064862713887785e-05,
      "loss": 4.4349,
      "step": 600
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.896538002387585e-05,
      "loss": 4.7823,
      "step": 610
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.8865897333863905e-05,
      "loss": 4.6077,
      "step": 620
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.876641464385197e-05,
      "loss": 4.6087,
      "step": 630
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.866693195384003e-05,
      "loss": 4.4584,
      "step": 640
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.8567449263828096e-05,
      "loss": 4.253,
      "step": 650
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.846796657381616e-05,
      "loss": 4.5562,
      "step": 660
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.836848388380422e-05,
      "loss": 4.664,
      "step": 670
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.8269001193792286e-05,
      "loss": 4.5417,
      "step": 680
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.816951850378034e-05,
      "loss": 4.5663,
      "step": 690
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.8070035813768406e-05,
      "loss": 4.6866,
      "step": 700
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.797055312375647e-05,
      "loss": 4.3267,
      "step": 710
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.787107043374453e-05,
      "loss": 4.3181,
      "step": 720
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.7771587743732597e-05,
      "loss": 4.4231,
      "step": 730
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.767210505372065e-05,
      "loss": 4.6145,
      "step": 740
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.757262236370872e-05,
      "loss": 4.2999,
      "step": 750
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.747313967369678e-05,
      "loss": 4.4095,
      "step": 760
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.737365698368484e-05,
      "loss": 4.3775,
      "step": 770
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.72741742936729e-05,
      "loss": 4.2196,
      "step": 780
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.7174691603660964e-05,
      "loss": 4.3921,
      "step": 790
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.707520891364903e-05,
      "loss": 4.2931,
      "step": 800
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.697572622363709e-05,
      "loss": 4.3394,
      "step": 810
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.6876243533625154e-05,
      "loss": 4.5654,
      "step": 820
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.677676084361322e-05,
      "loss": 4.5132,
      "step": 830
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.667727815360128e-05,
      "loss": 4.3988,
      "step": 840
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.657779546358934e-05,
      "loss": 4.3639,
      "step": 850
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.64783127735774e-05,
      "loss": 4.2684,
      "step": 860
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.637883008356546e-05,
      "loss": 4.3957,
      "step": 870
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.627934739355352e-05,
      "loss": 4.2517,
      "step": 880
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.6179864703541585e-05,
      "loss": 4.4408,
      "step": 890
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.608038201352965e-05,
      "loss": 4.6006,
      "step": 900
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.598089932351771e-05,
      "loss": 4.319,
      "step": 910
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.5881416633505775e-05,
      "loss": 4.2353,
      "step": 920
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.578193394349383e-05,
      "loss": 4.3487,
      "step": 930
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.5682451253481895e-05,
      "loss": 4.3522,
      "step": 940
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.558296856346996e-05,
      "loss": 4.2719,
      "step": 950
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.548348587345802e-05,
      "loss": 4.3681,
      "step": 960
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.5384003183446085e-05,
      "loss": 4.2045,
      "step": 970
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.528452049343415e-05,
      "loss": 4.0793,
      "step": 980
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.5185037803422205e-05,
      "loss": 4.3648,
      "step": 990
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.508555511341027e-05,
      "loss": 4.3136,
      "step": 1000
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.4986072423398326e-05,
      "loss": 4.231,
      "step": 1010
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.488658973338639e-05,
      "loss": 4.2073,
      "step": 1020
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.478710704337445e-05,
      "loss": 4.1859,
      "step": 1030
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.4687624353362516e-05,
      "loss": 4.2752,
      "step": 1040
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.458814166335058e-05,
      "loss": 4.2188,
      "step": 1050
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.448865897333864e-05,
      "loss": 4.0473,
      "step": 1060
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.4389176283326706e-05,
      "loss": 4.2626,
      "step": 1070
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.428969359331476e-05,
      "loss": 4.3355,
      "step": 1080
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.4190210903302826e-05,
      "loss": 4.1622,
      "step": 1090
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.409072821329089e-05,
      "loss": 3.9806,
      "step": 1100
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.399124552327895e-05,
      "loss": 4.1411,
      "step": 1110
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.389176283326702e-05,
      "loss": 3.9965,
      "step": 1120
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.3792280143255073e-05,
      "loss": 4.2456,
      "step": 1130
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.369279745324314e-05,
      "loss": 4.2537,
      "step": 1140
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.35933147632312e-05,
      "loss": 4.1966,
      "step": 1150
    },
    {
      "epoch": 0.63,
      "learning_rate": 4.349383207321926e-05,
      "loss": 4.184,
      "step": 1160
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.339434938320732e-05,
      "loss": 4.3061,
      "step": 1170
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.3294866693195384e-05,
      "loss": 4.1263,
      "step": 1180
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.319538400318345e-05,
      "loss": 4.0179,
      "step": 1190
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.309590131317151e-05,
      "loss": 4.3356,
      "step": 1200
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.2996418623159574e-05,
      "loss": 4.2516,
      "step": 1210
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.289693593314764e-05,
      "loss": 4.0807,
      "step": 1220
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.27974532431357e-05,
      "loss": 4.2358,
      "step": 1230
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.269797055312376e-05,
      "loss": 4.0623,
      "step": 1240
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.259848786311182e-05,
      "loss": 4.0085,
      "step": 1250
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.2499005173099885e-05,
      "loss": 4.0319,
      "step": 1260
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.239952248308794e-05,
      "loss": 4.2724,
      "step": 1270
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.2300039793076005e-05,
      "loss": 4.0002,
      "step": 1280
    },
    {
      "epoch": 0.7,
      "learning_rate": 4.220055710306407e-05,
      "loss": 4.1093,
      "step": 1290
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.210107441305213e-05,
      "loss": 3.8789,
      "step": 1300
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.2001591723040195e-05,
      "loss": 4.074,
      "step": 1310
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.190210903302825e-05,
      "loss": 4.0239,
      "step": 1320
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.1802626343016315e-05,
      "loss": 3.9218,
      "step": 1330
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.170314365300438e-05,
      "loss": 4.1213,
      "step": 1340
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.160366096299244e-05,
      "loss": 3.8113,
      "step": 1350
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.1504178272980506e-05,
      "loss": 4.1426,
      "step": 1360
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.140469558296857e-05,
      "loss": 3.9521,
      "step": 1370
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.130521289295663e-05,
      "loss": 3.9135,
      "step": 1380
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.120573020294469e-05,
      "loss": 4.0402,
      "step": 1390
    },
    {
      "epoch": 0.76,
      "learning_rate": 4.110624751293275e-05,
      "loss": 3.7249,
      "step": 1400
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.100676482292081e-05,
      "loss": 4.0509,
      "step": 1410
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.090728213290887e-05,
      "loss": 4.0897,
      "step": 1420
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.0807799442896936e-05,
      "loss": 4.0436,
      "step": 1430
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.0708316752885e-05,
      "loss": 4.1515,
      "step": 1440
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.060883406287306e-05,
      "loss": 4.1283,
      "step": 1450
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.0509351372861127e-05,
      "loss": 4.0683,
      "step": 1460
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.040986868284918e-05,
      "loss": 4.0861,
      "step": 1470
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.031038599283725e-05,
      "loss": 3.8385,
      "step": 1480
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.021090330282531e-05,
      "loss": 3.9456,
      "step": 1490
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.0111420612813374e-05,
      "loss": 3.9821,
      "step": 1500
    },
    {
      "epoch": 0.82,
      "learning_rate": 4.001193792280144e-05,
      "loss": 4.0357,
      "step": 1510
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.99124552327895e-05,
      "loss": 3.8475,
      "step": 1520
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.981297254277756e-05,
      "loss": 3.9357,
      "step": 1530
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.971348985276562e-05,
      "loss": 3.9567,
      "step": 1540
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.961400716275368e-05,
      "loss": 3.7954,
      "step": 1550
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.951452447274174e-05,
      "loss": 4.1068,
      "step": 1560
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.9415041782729804e-05,
      "loss": 3.9982,
      "step": 1570
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.931555909271787e-05,
      "loss": 3.8098,
      "step": 1580
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.921607640270593e-05,
      "loss": 4.0862,
      "step": 1590
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.9116593712693994e-05,
      "loss": 3.8756,
      "step": 1600
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.901711102268206e-05,
      "loss": 3.9807,
      "step": 1610
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.891762833267012e-05,
      "loss": 3.8607,
      "step": 1620
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.881814564265818e-05,
      "loss": 3.9816,
      "step": 1630
    },
    {
      "epoch": 0.89,
      "learning_rate": 3.871866295264624e-05,
      "loss": 3.8242,
      "step": 1640
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.8619180262634305e-05,
      "loss": 3.9258,
      "step": 1650
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.851969757262237e-05,
      "loss": 3.7072,
      "step": 1660
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.8420214882610425e-05,
      "loss": 3.9346,
      "step": 1670
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.832073219259849e-05,
      "loss": 3.9541,
      "step": 1680
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.822124950258655e-05,
      "loss": 4.1844,
      "step": 1690
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.8121766812574615e-05,
      "loss": 3.9096,
      "step": 1700
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.802228412256267e-05,
      "loss": 4.0237,
      "step": 1710
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.7922801432550736e-05,
      "loss": 3.9783,
      "step": 1720
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.78233187425388e-05,
      "loss": 3.9632,
      "step": 1730
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.772383605252686e-05,
      "loss": 3.9782,
      "step": 1740
    },
    {
      "epoch": 0.95,
      "learning_rate": 3.7624353362514926e-05,
      "loss": 3.9755,
      "step": 1750
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.752487067250299e-05,
      "loss": 3.8748,
      "step": 1760
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.742538798249105e-05,
      "loss": 3.9452,
      "step": 1770
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.7325905292479116e-05,
      "loss": 3.9216,
      "step": 1780
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.722642260246717e-05,
      "loss": 3.7036,
      "step": 1790
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.7126939912455236e-05,
      "loss": 3.829,
      "step": 1800
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.702745722244329e-05,
      "loss": 3.9101,
      "step": 1810
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.6927974532431356e-05,
      "loss": 3.8335,
      "step": 1820
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.682849184241942e-05,
      "loss": 3.7059,
      "step": 1830
    },
    {
      "epoch": 1.0,
      "learning_rate": 3.672900915240748e-05,
      "loss": 3.9,
      "step": 1840
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.806270122528076,
      "eval_runtime": 3.6526,
      "eval_samples_per_second": 223.951,
      "eval_steps_per_second": 28.199,
      "step": 1842
    }
  ],
  "logging_steps": 10,
  "max_steps": 5526,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 2157583420661760.0,
  "trial_name": null,
  "trial_params": null
}
