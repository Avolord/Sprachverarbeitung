{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1842,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 7.000000000000001e-07,
      "loss": 4.1238,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 4.2778,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 2.6e-06,
      "loss": 3.6836,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.6e-06,
      "loss": 3.4882,
      "step": 40
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.6e-06,
      "loss": 3.276,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.600000000000001e-06,
      "loss": 2.8453,
      "step": 60
    },
    {
      "epoch": 0.04,
      "learning_rate": 6.6e-06,
      "loss": 2.7673,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.6e-06,
      "loss": 2.6002,
      "step": 80
    },
    {
      "epoch": 0.05,
      "learning_rate": 8.599999999999999e-06,
      "loss": 2.7226,
      "step": 90
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.600000000000001e-06,
      "loss": 2.3658,
      "step": 100
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.06e-05,
      "loss": 2.5908,
      "step": 110
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.16e-05,
      "loss": 2.6223,
      "step": 120
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 2.5216,
      "step": 130
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 2.427,
      "step": 140
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 2.4434,
      "step": 150
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.56e-05,
      "loss": 2.2603,
      "step": 160
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.66e-05,
      "loss": 2.1165,
      "step": 170
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.76e-05,
      "loss": 2.2709,
      "step": 180
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.86e-05,
      "loss": 2.3629,
      "step": 190
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 2.3041,
      "step": 200
    },
    {
      "epoch": 0.11,
      "learning_rate": 2.06e-05,
      "loss": 2.2526,
      "step": 210
    },
    {
      "epoch": 0.12,
      "learning_rate": 2.16e-05,
      "loss": 2.1865,
      "step": 220
    },
    {
      "epoch": 0.12,
      "learning_rate": 2.26e-05,
      "loss": 2.134,
      "step": 230
    },
    {
      "epoch": 0.13,
      "learning_rate": 2.36e-05,
      "loss": 2.2522,
      "step": 240
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.46e-05,
      "loss": 2.1613,
      "step": 250
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 2.1523,
      "step": 260
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 2.5746,
      "step": 270
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 2.4033,
      "step": 280
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.86e-05,
      "loss": 2.1446,
      "step": 290
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.95e-05,
      "loss": 2.2992,
      "step": 300
    },
    {
      "epoch": 0.17,
      "learning_rate": 3.05e-05,
      "loss": 2.3018,
      "step": 310
    },
    {
      "epoch": 0.17,
      "learning_rate": 3.15e-05,
      "loss": 2.1644,
      "step": 320
    },
    {
      "epoch": 0.18,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.1986,
      "step": 330
    },
    {
      "epoch": 0.18,
      "learning_rate": 3.35e-05,
      "loss": 2.1978,
      "step": 340
    },
    {
      "epoch": 0.19,
      "learning_rate": 3.45e-05,
      "loss": 2.2351,
      "step": 350
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.55e-05,
      "loss": 2.3391,
      "step": 360
    },
    {
      "epoch": 0.2,
      "learning_rate": 3.65e-05,
      "loss": 2.0747,
      "step": 370
    },
    {
      "epoch": 0.21,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.254,
      "step": 380
    },
    {
      "epoch": 0.21,
      "learning_rate": 3.85e-05,
      "loss": 2.1802,
      "step": 390
    },
    {
      "epoch": 0.22,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 2.1411,
      "step": 400
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.05e-05,
      "loss": 2.2402,
      "step": 410
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.15e-05,
      "loss": 1.9396,
      "step": 420
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.25e-05,
      "loss": 2.2421,
      "step": 430
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.35e-05,
      "loss": 2.1205,
      "step": 440
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 2.1586,
      "step": 450
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.55e-05,
      "loss": 2.115,
      "step": 460
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 2.0317,
      "step": 470
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.75e-05,
      "loss": 2.0841,
      "step": 480
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.85e-05,
      "loss": 2.1718,
      "step": 490
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.1112,
      "step": 500
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.995025865499403e-05,
      "loss": 2.0772,
      "step": 510
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.9850775964982094e-05,
      "loss": 2.0756,
      "step": 520
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.975129327497016e-05,
      "loss": 2.1037,
      "step": 530
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.965181058495822e-05,
      "loss": 2.0236,
      "step": 540
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.9552327894946285e-05,
      "loss": 2.0775,
      "step": 550
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.945284520493435e-05,
      "loss": 2.1674,
      "step": 560
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.9353362514922405e-05,
      "loss": 2.1035,
      "step": 570
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.925387982491047e-05,
      "loss": 2.0835,
      "step": 580
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.9154397134898525e-05,
      "loss": 1.9846,
      "step": 590
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.905491444488659e-05,
      "loss": 2.1251,
      "step": 600
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.895543175487465e-05,
      "loss": 2.0441,
      "step": 610
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.8855949064862715e-05,
      "loss": 2.204,
      "step": 620
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.875646637485078e-05,
      "loss": 2.0242,
      "step": 630
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.865698368483884e-05,
      "loss": 2.1436,
      "step": 640
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.8557500994826905e-05,
      "loss": 2.1083,
      "step": 650
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.845801830481497e-05,
      "loss": 2.038,
      "step": 660
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.836848388380422e-05,
      "loss": 2.1536,
      "step": 670
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.8269001193792286e-05,
      "loss": 2.144,
      "step": 680
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.816951850378034e-05,
      "loss": 2.1609,
      "step": 690
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.8070035813768406e-05,
      "loss": 2.2662,
      "step": 700
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.797055312375647e-05,
      "loss": 2.0517,
      "step": 710
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.788101870274572e-05,
      "loss": 2.0766,
      "step": 720
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.778153601273379e-05,
      "loss": 2.0786,
      "step": 730
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.768205332272185e-05,
      "loss": 2.0345,
      "step": 740
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.7582570632709914e-05,
      "loss": 2.1202,
      "step": 750
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.748308794269797e-05,
      "loss": 2.0432,
      "step": 760
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.7383605252686034e-05,
      "loss": 2.0236,
      "step": 770
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.72841225626741e-05,
      "loss": 2.049,
      "step": 780
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.7184639872662154e-05,
      "loss": 1.9228,
      "step": 790
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.708515718265022e-05,
      "loss": 1.8439,
      "step": 800
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.698567449263828e-05,
      "loss": 2.154,
      "step": 810
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.6886191802626344e-05,
      "loss": 2.1013,
      "step": 820
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.678670911261441e-05,
      "loss": 2.082,
      "step": 830
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.668722642260247e-05,
      "loss": 1.8977,
      "step": 840
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.6587743732590535e-05,
      "loss": 1.9843,
      "step": 850
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.64882610425786e-05,
      "loss": 2.0245,
      "step": 860
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.6388778352566655e-05,
      "loss": 2.0784,
      "step": 870
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.628929566255472e-05,
      "loss": 1.973,
      "step": 880
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.618981297254278e-05,
      "loss": 2.0485,
      "step": 890
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.609033028253084e-05,
      "loss": 1.9928,
      "step": 900
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.59908475925189e-05,
      "loss": 1.874,
      "step": 910
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.5891364902506965e-05,
      "loss": 1.945,
      "step": 920
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.579188221249503e-05,
      "loss": 1.9061,
      "step": 930
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.569239952248309e-05,
      "loss": 2.0738,
      "step": 940
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.559291683247115e-05,
      "loss": 2.0659,
      "step": 950
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.549343414245921e-05,
      "loss": 2.1097,
      "step": 960
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.5393951452447276e-05,
      "loss": 2.1584,
      "step": 970
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.529446876243534e-05,
      "loss": 1.9223,
      "step": 980
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.51949860724234e-05,
      "loss": 1.9783,
      "step": 990
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.5095503382411466e-05,
      "loss": 1.9623,
      "step": 1000
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.499602069239953e-05,
      "loss": 1.9489,
      "step": 1010
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.4896538002387586e-05,
      "loss": 1.938,
      "step": 1020
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.479705531237565e-05,
      "loss": 1.992,
      "step": 1030
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.4697572622363706e-05,
      "loss": 1.9895,
      "step": 1040
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.459808993235177e-05,
      "loss": 2.0576,
      "step": 1050
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.449860724233983e-05,
      "loss": 1.8944,
      "step": 1060
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.4399124552327897e-05,
      "loss": 2.0927,
      "step": 1070
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.429964186231596e-05,
      "loss": 2.0468,
      "step": 1080
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.4200159172304023e-05,
      "loss": 2.1301,
      "step": 1090
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.410067648229209e-05,
      "loss": 2.1249,
      "step": 1100
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.4001193792280144e-05,
      "loss": 1.9189,
      "step": 1110
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.390171110226821e-05,
      "loss": 2.0968,
      "step": 1120
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.380222841225627e-05,
      "loss": 2.0923,
      "step": 1130
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.3702745722244334e-05,
      "loss": 1.9767,
      "step": 1140
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.36032630322324e-05,
      "loss": 1.9726,
      "step": 1150
    },
    {
      "epoch": 0.63,
      "learning_rate": 4.3503780342220454e-05,
      "loss": 1.9148,
      "step": 1160
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.340429765220852e-05,
      "loss": 1.8335,
      "step": 1170
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.330481496219658e-05,
      "loss": 1.9463,
      "step": 1180
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.320533227218464e-05,
      "loss": 2.0586,
      "step": 1190
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.31058495821727e-05,
      "loss": 2.1162,
      "step": 1200
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.3006366892160765e-05,
      "loss": 1.9877,
      "step": 1210
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.290688420214883e-05,
      "loss": 1.8917,
      "step": 1220
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.280740151213689e-05,
      "loss": 1.8944,
      "step": 1230
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.2707918822124955e-05,
      "loss": 1.9427,
      "step": 1240
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.260843613211302e-05,
      "loss": 1.9407,
      "step": 1250
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.2508953442101075e-05,
      "loss": 1.8868,
      "step": 1260
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.240947075208914e-05,
      "loss": 1.9551,
      "step": 1270
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.23099880620772e-05,
      "loss": 1.9995,
      "step": 1280
    },
    {
      "epoch": 0.7,
      "learning_rate": 4.2210505372065265e-05,
      "loss": 1.9469,
      "step": 1290
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.211102268205332e-05,
      "loss": 1.8753,
      "step": 1300
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.2011539992041385e-05,
      "loss": 1.8981,
      "step": 1310
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.191205730202945e-05,
      "loss": 1.9855,
      "step": 1320
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.181257461201751e-05,
      "loss": 1.95,
      "step": 1330
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.171309192200557e-05,
      "loss": 1.8274,
      "step": 1340
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.161360923199363e-05,
      "loss": 1.9386,
      "step": 1350
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.1514126541981696e-05,
      "loss": 1.9281,
      "step": 1360
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.141464385196976e-05,
      "loss": 1.9759,
      "step": 1370
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.131516116195782e-05,
      "loss": 1.9249,
      "step": 1380
    },
    {
      "epoch": 0.75,
      "learning_rate": 4.1215678471945886e-05,
      "loss": 1.8806,
      "step": 1390
    },
    {
      "epoch": 0.76,
      "learning_rate": 4.111619578193395e-05,
      "loss": 1.8697,
      "step": 1400
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.101671309192201e-05,
      "loss": 2.0003,
      "step": 1410
    },
    {
      "epoch": 0.77,
      "learning_rate": 4.091723040191007e-05,
      "loss": 1.8515,
      "step": 1420
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.081774771189813e-05,
      "loss": 1.9709,
      "step": 1430
    },
    {
      "epoch": 0.78,
      "learning_rate": 4.071826502188619e-05,
      "loss": 1.9324,
      "step": 1440
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.061878233187425e-05,
      "loss": 1.8967,
      "step": 1450
    },
    {
      "epoch": 0.79,
      "learning_rate": 4.051929964186232e-05,
      "loss": 1.969,
      "step": 1460
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.041981695185038e-05,
      "loss": 1.9676,
      "step": 1470
    },
    {
      "epoch": 0.8,
      "learning_rate": 4.0320334261838444e-05,
      "loss": 1.9475,
      "step": 1480
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.022085157182651e-05,
      "loss": 1.9649,
      "step": 1490
    },
    {
      "epoch": 0.81,
      "learning_rate": 4.0121368881814564e-05,
      "loss": 1.8201,
      "step": 1500
    },
    {
      "epoch": 0.82,
      "learning_rate": 4.002188619180263e-05,
      "loss": 1.852,
      "step": 1510
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.992240350179069e-05,
      "loss": 1.6849,
      "step": 1520
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.9822920811778754e-05,
      "loss": 2.0279,
      "step": 1530
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.972343812176682e-05,
      "loss": 1.825,
      "step": 1540
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.962395543175488e-05,
      "loss": 1.8778,
      "step": 1550
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.952447274174294e-05,
      "loss": 1.8689,
      "step": 1560
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.9424990051731e-05,
      "loss": 1.8524,
      "step": 1570
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.932550736171906e-05,
      "loss": 1.916,
      "step": 1580
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.922602467170712e-05,
      "loss": 1.8003,
      "step": 1590
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.9126541981695185e-05,
      "loss": 1.9867,
      "step": 1600
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.902705929168325e-05,
      "loss": 1.8321,
      "step": 1610
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.892757660167131e-05,
      "loss": 1.9368,
      "step": 1620
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.8828093911659375e-05,
      "loss": 1.891,
      "step": 1630
    },
    {
      "epoch": 0.89,
      "learning_rate": 3.872861122164744e-05,
      "loss": 1.8303,
      "step": 1640
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.8629128531635495e-05,
      "loss": 1.8426,
      "step": 1650
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.852964584162356e-05,
      "loss": 1.9905,
      "step": 1660
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.843016315161162e-05,
      "loss": 1.9109,
      "step": 1670
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.8330680461599686e-05,
      "loss": 1.8719,
      "step": 1680
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.823119777158775e-05,
      "loss": 1.7994,
      "step": 1690
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.8131715081575806e-05,
      "loss": 2.0427,
      "step": 1700
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.803223239156387e-05,
      "loss": 1.8973,
      "step": 1710
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.793274970155193e-05,
      "loss": 1.7659,
      "step": 1720
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.783326701153999e-05,
      "loss": 1.9902,
      "step": 1730
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.773378432152805e-05,
      "loss": 1.807,
      "step": 1740
    },
    {
      "epoch": 0.95,
      "learning_rate": 3.7634301631516116e-05,
      "loss": 1.9295,
      "step": 1750
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.753481894150418e-05,
      "loss": 1.7508,
      "step": 1760
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.743533625149224e-05,
      "loss": 1.8192,
      "step": 1770
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.7335853561480306e-05,
      "loss": 2.0006,
      "step": 1780
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.723637087146837e-05,
      "loss": 1.818,
      "step": 1790
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.713688818145643e-05,
      "loss": 1.9587,
      "step": 1800
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.703740549144449e-05,
      "loss": 1.7704,
      "step": 1810
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.6937922801432553e-05,
      "loss": 1.8655,
      "step": 1820
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.683844011142061e-05,
      "loss": 1.9573,
      "step": 1830
    },
    {
      "epoch": 1.0,
      "learning_rate": 3.6738957421408674e-05,
      "loss": 1.9214,
      "step": 1840
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.7053661346435547,
      "eval_runtime": 4.0891,
      "eval_samples_per_second": 200.042,
      "eval_steps_per_second": 25.189,
      "step": 1842
    }
  ],
  "logging_steps": 10,
  "max_steps": 5526,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 2281245596098560.0,
  "trial_name": null,
  "trial_params": null
}
