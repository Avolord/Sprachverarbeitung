{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import the metrics\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import BERTScorer\n",
    "#from evaluation.readability import flesch_kincaid_grade_level, dale_chall_readability_score, coleman_liau_index, lens\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from samsum_dataset.preprocessing import remove_oov_words, clean_dataset, wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_dataset() -> Dataset:\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(\"Samsung/samsum\", \"samsum\", trust_remote_code=True)\n",
    "    \n",
    "    #shuffle the train and validation sets\n",
    "    #dataset['train'] = dataset['train'].shuffle()\n",
    "    #dataset['validation'] = dataset['validation'].shuffle()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = _load_dataset()\n",
    "dataset2 = _load_dataset()\n",
    "dataset3 = _load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary:   0%|          | 0/14732 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14732/14732 [00:01<00:00, 9330.76it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset2 = clean_dataset(dataset2)\n",
    "dataset2 = remove_oov_words(dataset2)\n",
    "# from samsum_dataset.preprocessing import expand_contractions\n",
    "# def preprocess(entry):\n",
    "#     entry['dialogue'] = expand_contractions(entry['dialogue'])\n",
    "#     return entry\n",
    "\n",
    "# dataset2['test'] = dataset2['test'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hannah hey do you have betty s number amanda let me check hannah file_gif amanda sorry cannot find it amanda ask larry amanda he called her last time we were at the park together hannah i do not know him well hannah file_gif amanda do not be shy he is very nice hannah if you say so hannah i would rather you texted him amanda just text him hannah urgh alright hannah bye amanda bye bye'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['test'][0]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the dataset for split train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 2595/14732 [00:00<00:02, 4308.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary for the train dataset is same for the entry 1760.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5633/14732 [00:01<00:02, 4290.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary for the train dataset is same for the entry 4889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 6928/14732 [00:01<00:01, 4292.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary for the train dataset is same for the entry 6054.\n",
      "The dialogue for the train dataset is same for the entry 6054.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14732/14732 [00:03<00:00, 4256.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the dataset for split validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 818/818 [00:00<00:00, 4421.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the dataset for split test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 819/819 [00:00<00:00, 3800.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#compare the two datasets\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(\"Testing the dataset for split\", split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset1[split]))):\n",
    "        if dataset1[split][i]['summary'] == dataset2[split][i]['summary']:\n",
    "            print(f\"The summary for the {split} dataset is same for the entry {i}.\")\n",
    "            \n",
    "        if dataset1[split][i]['dialogue'] == dataset2[split][i]['dialogue']:\n",
    "            print(f\"The dialogue for the {split} dataset is same for the entry {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['validation', 'test']:\n",
    "    print(\"Testing the dataset for split\", split)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset2[split]))):\n",
    "        #check if any of the splits contain the word 'unk'\n",
    "        if 'unk' in dataset2[split][i]['summary'] or 'unk' in dataset2[split][i]['dialogue']:\n",
    "            print(f\"The summary for the {split} dataset contains the word 'unk' for the entry {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 5.26047420501709 secs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8953b079e4534419a81989559a3ef848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset3 = wsd(dataset3, ['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hannah : Hey , do you have Betty 's phone_number.n.01 ? Amanda : lunar_excursion_module.n.01 me determine.v.08 Hannah : < file_gif > Amanda : regretful.a.01 , california.n.01 n't find.v.05 it . Amanda : ask.v.04 Larry Amanda : He shout.v.02 her last.a.02 time.n.06 we were at the parking_lot.n.01 together.r.04 Hannah : I do n't know.v.07 him well.r.09 Hannah : < file_gif > Amanda : Do n't be diffident.a.02 , he 's very nice.s.03 Hannah : If you say.v.10 so.. Hannah : I 'd rather.r.02 you textbook.n.01 him Amanda : Just textbook.n.01 him ðŸ™‚ Hannah : Urgh.. very_well.r.02 Hannah : adieu.n.01 Amanda : adieu.n.01 adieu.n.01\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3['test'][0]['dialogue']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelfinetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
