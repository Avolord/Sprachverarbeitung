{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]\n",
    "# !pip install pandas\n",
    "# !pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc10a36e00d47a8bfb3419f5872edb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "corpus.7z:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21db9f88de74c2396f450761f0b7c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413eee01b511474f9eb55a738bf9b317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9a02244deb498cb080b9d4e49394e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Samsung/samsum\", \"samsum\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary'],\n",
       "    num_rows: 14732\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elife_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melife_dataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_dataset\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m clean_dataset(dataset)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elife_dataset'"
     ]
    }
   ],
   "source": [
    "from elife_dataset.preprocessing import clean_dataset\n",
    "dataset = clean_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMSumDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        dialogue = item['dialogue']\n",
    "        summary = item['summary']\n",
    "        inputs = self.tokenizer(dialogue, return_tensors='pt', max_length=512, truncation=True)\n",
    "        targets = self.tokenizer(summary, return_tensors='pt', max_length=128, truncation=True)\n",
    "        return {\n",
    "            'input_ids': inputs.input_ids.flatten(),\n",
    "            'attention_mask': inputs.attention_mask.flatten(),\n",
    "            'labels': targets.input_ids.flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"facebook/bart-base\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dataset = DailyMailDataset(validation_data, tokenizer)\n",
    "train = SAMSumDataset(dataset['train'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_dataset = DailyMailDataset(train_data, tokenizer)\n",
    "validation = SAMSumDataset(dataset['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\accelerate\\accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "c:\\Users\\theav\\miniconda3\\envs\\modelfinetune\\Lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Create a data collator specifically for sequence-to-sequence models\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,  # This ensures dynamic padding within each batch\n",
    "    label_pad_token_id=-100  # Ensures labels are padded with -100 for loss calculation\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='training',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=validation,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491ade96999748ea98c14263de444fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3596, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.01}\n",
      "{'loss': 4.1931, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 3.9124, 'learning_rate': 2.7e-06, 'epoch': 0.02}\n",
      "{'loss': 3.3269, 'learning_rate': 3.7e-06, 'epoch': 0.02}\n",
      "{'loss': 2.6702, 'learning_rate': 4.7e-06, 'epoch': 0.03}\n",
      "{'loss': 2.3419, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.03}\n",
      "{'loss': 2.4545, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 2.3389, 'learning_rate': 7.6e-06, 'epoch': 0.04}\n",
      "{'loss': 2.419, 'learning_rate': 8.599999999999999e-06, 'epoch': 0.05}\n",
      "{'loss': 2.2155, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 2.2253, 'learning_rate': 1.06e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2492, 'learning_rate': 1.16e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1021, 'learning_rate': 1.2600000000000001e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1877, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1849, 'learning_rate': 1.4599999999999999e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0184, 'learning_rate': 1.56e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1624, 'learning_rate': 1.66e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0525, 'learning_rate': 1.76e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1473, 'learning_rate': 1.86e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1087, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9971, 'learning_rate': 2.06e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0642, 'learning_rate': 2.16e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0047, 'learning_rate': 2.26e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0221, 'learning_rate': 2.36e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1018, 'learning_rate': 2.46e-05, 'epoch': 0.14}\n",
      "{'loss': 2.0014, 'learning_rate': 2.5600000000000002e-05, 'epoch': 0.14}\n",
      "{'loss': 2.0635, 'learning_rate': 2.6600000000000003e-05, 'epoch': 0.15}\n",
      "{'loss': 2.0699, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8901, 'learning_rate': 2.86e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0132, 'learning_rate': 2.96e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9738, 'learning_rate': 3.06e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0502, 'learning_rate': 3.16e-05, 'epoch': 0.17}\n",
      "{'loss': 1.954, 'learning_rate': 3.26e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0499, 'learning_rate': 3.3600000000000004e-05, 'epoch': 0.18}\n",
      "{'loss': 2.062, 'learning_rate': 3.46e-05, 'epoch': 0.19}\n",
      "{'loss': 2.0973, 'learning_rate': 3.56e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9432, 'learning_rate': 3.66e-05, 'epoch': 0.2}\n",
      "{'loss': 2.0279, 'learning_rate': 3.76e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0147, 'learning_rate': 3.86e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9802, 'learning_rate': 3.960000000000001e-05, 'epoch': 0.22}\n",
      "{'loss': 2.0612, 'learning_rate': 4.0600000000000004e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8926, 'learning_rate': 4.16e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9704, 'learning_rate': 4.26e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9881, 'learning_rate': 4.36e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0402, 'learning_rate': 4.46e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0542, 'learning_rate': 4.5600000000000004e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1172, 'learning_rate': 4.660000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9134, 'learning_rate': 4.76e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9456, 'learning_rate': 4.86e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0087, 'learning_rate': 4.96e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0678, 'learning_rate': 4.994031038599284e-05, 'epoch': 0.28}\n",
      "{'loss': 2.0155, 'learning_rate': 4.9840827695980904e-05, 'epoch': 0.28}\n",
      "{'loss': 2.0815, 'learning_rate': 4.974134500596897e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9122, 'learning_rate': 4.9641862315957024e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0368, 'learning_rate': 4.954237962594509e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9432, 'learning_rate': 4.9442896935933144e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9388, 'learning_rate': 4.934341424592121e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9193, 'learning_rate': 4.924393155590927e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9806, 'learning_rate': 4.9144448865897334e-05, 'epoch': 0.32}\n",
      "{'loss': 1.73, 'learning_rate': 4.90449661758854e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0315, 'learning_rate': 4.894548348587346e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8759, 'learning_rate': 4.8846000795861525e-05, 'epoch': 0.34}\n",
      "{'loss': 2.0049, 'learning_rate': 4.874651810584959e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9926, 'learning_rate': 4.8647035415837645e-05, 'epoch': 0.35}\n",
      "{'loss': 1.903, 'learning_rate': 4.854755272582571e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9865, 'learning_rate': 4.844807003581377e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7182, 'learning_rate': 4.8348587345801835e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9157, 'learning_rate': 4.824910465578989e-05, 'epoch': 0.37}\n",
      "{'loss': 2.0103, 'learning_rate': 4.8149621965777955e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9377, 'learning_rate': 4.805013927576602e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9165, 'learning_rate': 4.795065658575408e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9093, 'learning_rate': 4.7861122164743336e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9005, 'learning_rate': 4.77616394747314e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9493, 'learning_rate': 4.7662156784719456e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9012, 'learning_rate': 4.756267409470752e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9302, 'learning_rate': 4.746319140469558e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9928, 'learning_rate': 4.7363708714683646e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0409, 'learning_rate': 4.726422602467171e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8238, 'learning_rate': 4.716474333465977e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7508, 'learning_rate': 4.706526064464784e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7367, 'learning_rate': 4.69657779546359e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8927, 'learning_rate': 4.686629526462396e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8759, 'learning_rate': 4.676681257461202e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0369, 'learning_rate': 4.6667329884600084e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9133, 'learning_rate': 4.656784719458814e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9046, 'learning_rate': 4.6468364504576204e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8257, 'learning_rate': 4.636888181456427e-05, 'epoch': 0.47}\n",
      "{'loss': 2.0019, 'learning_rate': 4.626939912455233e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8773, 'learning_rate': 4.6169916434540394e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9023, 'learning_rate': 4.607043374452845e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8118, 'learning_rate': 4.5970951054516514e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8958, 'learning_rate': 4.587146836450458e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8745, 'learning_rate': 4.577198567449264e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7892, 'learning_rate': 4.5672502984480705e-05, 'epoch': 0.51}\n",
      "{'loss': 2.0158, 'learning_rate': 4.557302029446877e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8209, 'learning_rate': 4.547353760445683e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7654, 'learning_rate': 4.537405491444489e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8067, 'learning_rate': 4.527457222443295e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9001, 'learning_rate': 4.517508953442101e-05, 'epoch': 0.54}\n",
      "{'loss': 1.899, 'learning_rate': 4.507560684440907e-05, 'epoch': 0.54}\n",
      "{'loss': 1.808, 'learning_rate': 4.4976124154397135e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8775, 'learning_rate': 4.48766414643852e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8769, 'learning_rate': 4.477715877437326e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9092, 'learning_rate': 4.4677676084361326e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9257, 'learning_rate': 4.457819339434939e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9594, 'learning_rate': 4.4478710704337446e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9593, 'learning_rate': 4.437922801432551e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7715, 'learning_rate': 4.427974532431357e-05, 'epoch': 0.59}\n",
      "{'loss': 2.0011, 'learning_rate': 4.4180262634301636e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7937, 'learning_rate': 4.40807799442897e-05, 'epoch': 0.6}\n",
      "{'loss': 1.964, 'learning_rate': 4.3981297254277756e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7923, 'learning_rate': 4.388181456426582e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8331, 'learning_rate': 4.378233187425388e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9209, 'learning_rate': 4.368284918424194e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0791, 'learning_rate': 4.358336649423e-05, 'epoch': 0.62}\n",
      "{'loss': 1.942, 'learning_rate': 4.348388380421807e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7526, 'learning_rate': 4.338440111420613e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8142, 'learning_rate': 4.3284918424194194e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9331, 'learning_rate': 4.318543573418226e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9251, 'learning_rate': 4.308595304417032e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8675, 'learning_rate': 4.298647035415838e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8613, 'learning_rate': 4.288698766414644e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8684, 'learning_rate': 4.2787504974134504e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8378, 'learning_rate': 4.268802228412256e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8712, 'learning_rate': 4.2588539594110624e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9462, 'learning_rate': 4.248905690409869e-05, 'epoch': 0.68}\n",
      "{'loss': 1.771, 'learning_rate': 4.238957421408675e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9359, 'learning_rate': 4.2290091524074815e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8296, 'learning_rate': 4.219060883406287e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7053, 'learning_rate': 4.2091126144050935e-05, 'epoch': 0.71}\n",
      "{'loss': 1.9347, 'learning_rate': 4.1991643454039e-05, 'epoch': 0.71}\n",
      "{'loss': 1.8368, 'learning_rate': 4.189216076402706e-05, 'epoch': 0.72}\n",
      "{'loss': 1.9627, 'learning_rate': 4.1792678074015125e-05, 'epoch': 0.72}\n",
      "{'loss': 1.8353, 'learning_rate': 4.169319538400319e-05, 'epoch': 0.73}\n",
      "{'loss': 1.7672, 'learning_rate': 4.159371269399125e-05, 'epoch': 0.73}\n",
      "{'loss': 1.7881, 'learning_rate': 4.149423000397931e-05, 'epoch': 0.74}\n",
      "{'loss': 1.8037, 'learning_rate': 4.139474731396737e-05, 'epoch': 0.74}\n",
      "{'loss': 1.8575, 'learning_rate': 4.129526462395543e-05, 'epoch': 0.75}\n",
      "{'loss': 1.7995, 'learning_rate': 4.119578193394349e-05, 'epoch': 0.75}\n",
      "{'loss': 1.923, 'learning_rate': 4.1096299243931556e-05, 'epoch': 0.76}\n",
      "{'loss': 1.8295, 'learning_rate': 4.099681655391962e-05, 'epoch': 0.77}\n",
      "{'loss': 1.8196, 'learning_rate': 4.089733386390768e-05, 'epoch': 0.77}\n",
      "{'loss': 1.8559, 'learning_rate': 4.0797851173895746e-05, 'epoch': 0.78}\n",
      "{'loss': 1.9056, 'learning_rate': 4.069836848388381e-05, 'epoch': 0.78}\n",
      "{'loss': 1.8169, 'learning_rate': 4.0598885793871866e-05, 'epoch': 0.79}\n",
      "{'loss': 1.7767, 'learning_rate': 4.049940310385993e-05, 'epoch': 0.79}\n",
      "{'loss': 1.8204, 'learning_rate': 4.039992041384799e-05, 'epoch': 0.8}\n",
      "{'loss': 1.8578, 'learning_rate': 4.0300437723836056e-05, 'epoch': 0.8}\n",
      "{'loss': 1.7935, 'learning_rate': 4.020095503382412e-05, 'epoch': 0.81}\n",
      "{'loss': 1.7981, 'learning_rate': 4.0101472343812177e-05, 'epoch': 0.81}\n",
      "{'loss': 1.7885, 'learning_rate': 4.000198965380024e-05, 'epoch': 0.82}\n",
      "{'loss': 1.9232, 'learning_rate': 3.9902506963788303e-05, 'epoch': 0.83}\n",
      "{'loss': 1.7616, 'learning_rate': 3.980302427377636e-05, 'epoch': 0.83}\n",
      "{'loss': 1.8259, 'learning_rate': 3.9703541583764424e-05, 'epoch': 0.84}\n",
      "{'loss': 1.8124, 'learning_rate': 3.960405889375249e-05, 'epoch': 0.84}\n",
      "{'loss': 1.9801, 'learning_rate': 3.950457620374055e-05, 'epoch': 0.85}\n",
      "{'loss': 1.6764, 'learning_rate': 3.9405093513728614e-05, 'epoch': 0.85}\n",
      "{'loss': 1.8734, 'learning_rate': 3.930561082371668e-05, 'epoch': 0.86}\n",
      "{'loss': 1.8213, 'learning_rate': 3.920612813370474e-05, 'epoch': 0.86}\n",
      "{'loss': 1.769, 'learning_rate': 3.9106645443692804e-05, 'epoch': 0.87}\n",
      "{'loss': 1.9161, 'learning_rate': 3.900716275368086e-05, 'epoch': 0.87}\n",
      "{'loss': 1.7811, 'learning_rate': 3.8907680063668924e-05, 'epoch': 0.88}\n",
      "{'loss': 1.8587, 'learning_rate': 3.880819737365699e-05, 'epoch': 0.88}\n",
      "{'loss': 1.9288, 'learning_rate': 3.8708714683645044e-05, 'epoch': 0.89}\n",
      "{'loss': 1.7761, 'learning_rate': 3.860923199363311e-05, 'epoch': 0.9}\n",
      "{'loss': 1.8257, 'learning_rate': 3.850974930362117e-05, 'epoch': 0.9}\n",
      "{'loss': 1.7879, 'learning_rate': 3.8410266613609235e-05, 'epoch': 0.91}\n",
      "{'loss': 1.7916, 'learning_rate': 3.831078392359729e-05, 'epoch': 0.91}\n",
      "{'loss': 1.8391, 'learning_rate': 3.8211301233585355e-05, 'epoch': 0.92}\n",
      "{'loss': 1.7617, 'learning_rate': 3.811181854357342e-05, 'epoch': 0.92}\n",
      "{'loss': 1.8463, 'learning_rate': 3.801233585356148e-05, 'epoch': 0.93}\n",
      "{'loss': 1.8966, 'learning_rate': 3.7912853163549545e-05, 'epoch': 0.93}\n",
      "{'loss': 1.7579, 'learning_rate': 3.781337047353761e-05, 'epoch': 0.94}\n",
      "{'loss': 1.7623, 'learning_rate': 3.771388778352567e-05, 'epoch': 0.94}\n",
      "{'loss': 1.7608, 'learning_rate': 3.7614405093513736e-05, 'epoch': 0.95}\n",
      "{'loss': 1.8278, 'learning_rate': 3.751492240350179e-05, 'epoch': 0.96}\n",
      "{'loss': 1.7849, 'learning_rate': 3.7415439713489856e-05, 'epoch': 0.96}\n",
      "{'loss': 1.8247, 'learning_rate': 3.731595702347791e-05, 'epoch': 0.97}\n",
      "{'loss': 1.7522, 'learning_rate': 3.7216474333465976e-05, 'epoch': 0.97}\n",
      "{'loss': 1.8917, 'learning_rate': 3.711699164345404e-05, 'epoch': 0.98}\n",
      "{'loss': 1.8198, 'learning_rate': 3.70175089534421e-05, 'epoch': 0.98}\n",
      "{'loss': 1.8079, 'learning_rate': 3.6918026263430166e-05, 'epoch': 0.99}\n",
      "{'loss': 1.8641, 'learning_rate': 3.681854357341823e-05, 'epoch': 0.99}\n",
      "{'loss': 1.7317, 'learning_rate': 3.6719060883406286e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7c0248a68b44e39b25b3d55a416952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5865745544433594, 'eval_runtime': 5.3283, 'eval_samples_per_second': 153.521, 'eval_steps_per_second': 19.331, 'epoch': 1.0}\n",
      "{'loss': 1.5573, 'learning_rate': 3.661957819339435e-05, 'epoch': 1.0}\n",
      "{'loss': 1.6778, 'learning_rate': 3.652009550338241e-05, 'epoch': 1.01}\n",
      "{'loss': 1.5912, 'learning_rate': 3.642061281337048e-05, 'epoch': 1.02}\n",
      "{'loss': 1.5042, 'learning_rate': 3.632113012335854e-05, 'epoch': 1.02}\n",
      "{'loss': 1.5853, 'learning_rate': 3.6221647433346604e-05, 'epoch': 1.03}\n",
      "{'loss': 1.6217, 'learning_rate': 3.612216474333466e-05, 'epoch': 1.03}\n",
      "{'loss': 1.6053, 'learning_rate': 3.6022682053322724e-05, 'epoch': 1.04}\n",
      "{'loss': 1.4938, 'learning_rate': 3.592319936331078e-05, 'epoch': 1.04}\n",
      "{'loss': 1.6211, 'learning_rate': 3.5823716673298844e-05, 'epoch': 1.05}\n",
      "{'loss': 1.5575, 'learning_rate': 3.572423398328691e-05, 'epoch': 1.05}\n",
      "{'loss': 1.4417, 'learning_rate': 3.562475129327497e-05, 'epoch': 1.06}\n",
      "{'loss': 1.627, 'learning_rate': 3.5525268603263034e-05, 'epoch': 1.06}\n",
      "{'loss': 1.4868, 'learning_rate': 3.54257859132511e-05, 'epoch': 1.07}\n",
      "{'loss': 1.6675, 'learning_rate': 3.532630322323916e-05, 'epoch': 1.07}\n",
      "{'loss': 1.5992, 'learning_rate': 3.5226820533227224e-05, 'epoch': 1.08}\n",
      "{'loss': 1.6209, 'learning_rate': 3.512733784321528e-05, 'epoch': 1.09}\n",
      "{'loss': 1.552, 'learning_rate': 3.5027855153203345e-05, 'epoch': 1.09}\n",
      "{'loss': 1.5357, 'learning_rate': 3.49383207321926e-05, 'epoch': 1.1}\n",
      "{'loss': 1.4686, 'learning_rate': 3.483883804218066e-05, 'epoch': 1.1}\n",
      "{'loss': 1.6029, 'learning_rate': 3.4739355352168725e-05, 'epoch': 1.11}\n",
      "{'loss': 1.5345, 'learning_rate': 3.463987266215679e-05, 'epoch': 1.11}\n",
      "{'loss': 1.473, 'learning_rate': 3.454038997214485e-05, 'epoch': 1.12}\n",
      "{'loss': 1.5745, 'learning_rate': 3.444090728213291e-05, 'epoch': 1.12}\n",
      "{'loss': 1.6216, 'learning_rate': 3.434142459212097e-05, 'epoch': 1.13}\n",
      "{'loss': 1.5747, 'learning_rate': 3.4241941902109036e-05, 'epoch': 1.13}\n",
      "{'loss': 1.6659, 'learning_rate': 3.414245921209709e-05, 'epoch': 1.14}\n",
      "{'loss': 1.5864, 'learning_rate': 3.4042976522085156e-05, 'epoch': 1.15}\n",
      "{'loss': 1.5473, 'learning_rate': 3.394349383207322e-05, 'epoch': 1.15}\n",
      "{'loss': 1.5679, 'learning_rate': 3.384401114206128e-05, 'epoch': 1.16}\n",
      "{'loss': 1.5772, 'learning_rate': 3.3744528452049346e-05, 'epoch': 1.16}\n",
      "{'loss': 1.5427, 'learning_rate': 3.364504576203741e-05, 'epoch': 1.17}\n",
      "{'loss': 1.6735, 'learning_rate': 3.354556307202547e-05, 'epoch': 1.17}\n",
      "{'loss': 1.5645, 'learning_rate': 3.3446080382013536e-05, 'epoch': 1.18}\n",
      "{'loss': 1.4943, 'learning_rate': 3.334659769200159e-05, 'epoch': 1.18}\n",
      "{'loss': 1.5151, 'learning_rate': 3.3247115001989657e-05, 'epoch': 1.19}\n",
      "{'loss': 1.533, 'learning_rate': 3.314763231197771e-05, 'epoch': 1.19}\n",
      "{'loss': 1.5136, 'learning_rate': 3.304814962196578e-05, 'epoch': 1.2}\n",
      "{'loss': 1.416, 'learning_rate': 3.294866693195384e-05, 'epoch': 1.21}\n",
      "{'loss': 1.558, 'learning_rate': 3.2849184241941904e-05, 'epoch': 1.21}\n",
      "{'loss': 1.5725, 'learning_rate': 3.274970155192997e-05, 'epoch': 1.22}\n",
      "{'loss': 1.5521, 'learning_rate': 3.265021886191803e-05, 'epoch': 1.22}\n",
      "{'loss': 1.4175, 'learning_rate': 3.255073617190609e-05, 'epoch': 1.23}\n",
      "{'loss': 1.4737, 'learning_rate': 3.245125348189415e-05, 'epoch': 1.23}\n",
      "{'loss': 1.5054, 'learning_rate': 3.2351770791882214e-05, 'epoch': 1.24}\n",
      "{'loss': 1.6104, 'learning_rate': 3.225228810187028e-05, 'epoch': 1.24}\n",
      "{'loss': 1.5636, 'learning_rate': 3.215280541185834e-05, 'epoch': 1.25}\n",
      "{'loss': 1.4681, 'learning_rate': 3.2053322721846404e-05, 'epoch': 1.25}\n",
      "{'loss': 1.4937, 'learning_rate': 3.195384003183446e-05, 'epoch': 1.26}\n",
      "{'loss': 1.6585, 'learning_rate': 3.1854357341822525e-05, 'epoch': 1.26}\n",
      "{'loss': 1.5962, 'learning_rate': 3.175487465181058e-05, 'epoch': 1.27}\n",
      "{'loss': 1.4481, 'learning_rate': 3.1655391961798645e-05, 'epoch': 1.28}\n",
      "{'loss': 1.4188, 'learning_rate': 3.155590927178671e-05, 'epoch': 1.28}\n",
      "{'loss': 1.6169, 'learning_rate': 3.145642658177477e-05, 'epoch': 1.29}\n",
      "{'loss': 1.4471, 'learning_rate': 3.1356943891762835e-05, 'epoch': 1.29}\n",
      "{'loss': 1.5209, 'learning_rate': 3.12574612017509e-05, 'epoch': 1.3}\n",
      "{'loss': 1.5603, 'learning_rate': 3.115797851173896e-05, 'epoch': 1.3}\n",
      "{'loss': 1.561, 'learning_rate': 3.105849582172702e-05, 'epoch': 1.31}\n",
      "{'loss': 1.6885, 'learning_rate': 3.095901313171508e-05, 'epoch': 1.31}\n",
      "{'loss': 1.7224, 'learning_rate': 3.0859530441703145e-05, 'epoch': 1.32}\n",
      "{'loss': 1.5191, 'learning_rate': 3.076004775169121e-05, 'epoch': 1.32}\n",
      "{'loss': 1.4192, 'learning_rate': 3.066056506167927e-05, 'epoch': 1.33}\n",
      "{'loss': 1.5561, 'learning_rate': 3.056108237166733e-05, 'epoch': 1.34}\n",
      "{'loss': 1.5305, 'learning_rate': 3.0461599681655396e-05, 'epoch': 1.34}\n",
      "{'loss': 1.5398, 'learning_rate': 3.036211699164346e-05, 'epoch': 1.35}\n",
      "{'loss': 1.6585, 'learning_rate': 3.0262634301631516e-05, 'epoch': 1.35}\n",
      "{'loss': 1.551, 'learning_rate': 3.016315161161958e-05, 'epoch': 1.36}\n",
      "{'loss': 1.5318, 'learning_rate': 3.006366892160764e-05, 'epoch': 1.36}\n",
      "{'loss': 1.5685, 'learning_rate': 2.9964186231595703e-05, 'epoch': 1.37}\n",
      "{'loss': 1.5265, 'learning_rate': 2.9864703541583766e-05, 'epoch': 1.37}\n",
      "{'loss': 1.6587, 'learning_rate': 2.976522085157183e-05, 'epoch': 1.38}\n",
      "{'loss': 1.6622, 'learning_rate': 2.9665738161559893e-05, 'epoch': 1.38}\n",
      "{'loss': 1.4734, 'learning_rate': 2.9566255471547953e-05, 'epoch': 1.39}\n",
      "{'loss': 1.6025, 'learning_rate': 2.9466772781536013e-05, 'epoch': 1.4}\n",
      "{'loss': 1.5474, 'learning_rate': 2.9367290091524073e-05, 'epoch': 1.4}\n",
      "{'loss': 1.5331, 'learning_rate': 2.9267807401512137e-05, 'epoch': 1.41}\n",
      "{'loss': 1.5046, 'learning_rate': 2.91683247115002e-05, 'epoch': 1.41}\n",
      "{'loss': 1.5225, 'learning_rate': 2.9068842021488264e-05, 'epoch': 1.42}\n",
      "{'loss': 1.5078, 'learning_rate': 2.8969359331476327e-05, 'epoch': 1.42}\n",
      "{'loss': 1.5982, 'learning_rate': 2.8869876641464387e-05, 'epoch': 1.43}\n",
      "{'loss': 1.6078, 'learning_rate': 2.877039395145245e-05, 'epoch': 1.43}\n",
      "{'loss': 1.584, 'learning_rate': 2.8670911261440507e-05, 'epoch': 1.44}\n",
      "{'loss': 1.4424, 'learning_rate': 2.857142857142857e-05, 'epoch': 1.44}\n",
      "{'loss': 1.3801, 'learning_rate': 2.8471945881416634e-05, 'epoch': 1.45}\n",
      "{'loss': 1.569, 'learning_rate': 2.8372463191404698e-05, 'epoch': 1.45}\n",
      "{'loss': 1.5424, 'learning_rate': 2.827298050139276e-05, 'epoch': 1.46}\n",
      "{'loss': 1.61, 'learning_rate': 2.817349781138082e-05, 'epoch': 1.47}\n",
      "{'loss': 1.5575, 'learning_rate': 2.8074015121368885e-05, 'epoch': 1.47}\n",
      "{'loss': 1.5729, 'learning_rate': 2.7974532431356948e-05, 'epoch': 1.48}\n",
      "{'loss': 1.653, 'learning_rate': 2.7875049741345005e-05, 'epoch': 1.48}\n",
      "{'loss': 1.5497, 'learning_rate': 2.7775567051333068e-05, 'epoch': 1.49}\n",
      "{'loss': 1.557, 'learning_rate': 2.7676084361321132e-05, 'epoch': 1.49}\n",
      "{'loss': 1.5288, 'learning_rate': 2.7576601671309192e-05, 'epoch': 1.5}\n",
      "{'loss': 1.5558, 'learning_rate': 2.7477118981297255e-05, 'epoch': 1.5}\n",
      "{'loss': 1.4192, 'learning_rate': 2.737763629128532e-05, 'epoch': 1.51}\n",
      "{'loss': 1.5561, 'learning_rate': 2.7278153601273382e-05, 'epoch': 1.51}\n",
      "{'loss': 1.5753, 'learning_rate': 2.717867091126144e-05, 'epoch': 1.52}\n",
      "{'loss': 1.3586, 'learning_rate': 2.7079188221249502e-05, 'epoch': 1.53}\n",
      "{'loss': 1.5839, 'learning_rate': 2.6979705531237566e-05, 'epoch': 1.53}\n",
      "{'loss': 1.635, 'learning_rate': 2.6880222841225626e-05, 'epoch': 1.54}\n",
      "{'loss': 1.5146, 'learning_rate': 2.678074015121369e-05, 'epoch': 1.54}\n",
      "{'loss': 1.5528, 'learning_rate': 2.6681257461201753e-05, 'epoch': 1.55}\n",
      "{'loss': 1.5309, 'learning_rate': 2.6581774771189816e-05, 'epoch': 1.55}\n",
      "{'loss': 1.5481, 'learning_rate': 2.648229208117788e-05, 'epoch': 1.56}\n",
      "{'loss': 1.4336, 'learning_rate': 2.6382809391165936e-05, 'epoch': 1.56}\n",
      "{'loss': 1.5017, 'learning_rate': 2.6283326701154e-05, 'epoch': 1.57}\n",
      "{'loss': 1.5384, 'learning_rate': 2.618384401114206e-05, 'epoch': 1.57}\n",
      "{'loss': 1.49, 'learning_rate': 2.6084361321130123e-05, 'epoch': 1.58}\n",
      "{'loss': 1.5922, 'learning_rate': 2.5984878631118187e-05, 'epoch': 1.59}\n",
      "{'loss': 1.6155, 'learning_rate': 2.588539594110625e-05, 'epoch': 1.59}\n",
      "{'loss': 1.454, 'learning_rate': 2.5785913251094314e-05, 'epoch': 1.6}\n",
      "{'loss': 1.6059, 'learning_rate': 2.5686430561082374e-05, 'epoch': 1.6}\n",
      "{'loss': 1.4434, 'learning_rate': 2.5586947871070434e-05, 'epoch': 1.61}\n",
      "{'loss': 1.4934, 'learning_rate': 2.5487465181058494e-05, 'epoch': 1.61}\n",
      "{'loss': 1.5773, 'learning_rate': 2.5387982491046557e-05, 'epoch': 1.62}\n",
      "{'loss': 1.5818, 'learning_rate': 2.528849980103462e-05, 'epoch': 1.62}\n",
      "{'loss': 1.376, 'learning_rate': 2.5189017111022684e-05, 'epoch': 1.63}\n",
      "{'loss': 1.5509, 'learning_rate': 2.5089534421010747e-05, 'epoch': 1.63}\n",
      "{'loss': 1.6095, 'learning_rate': 2.4990051730998808e-05, 'epoch': 1.64}\n",
      "{'loss': 1.5049, 'learning_rate': 2.4890569040986868e-05, 'epoch': 1.64}\n",
      "{'loss': 1.5591, 'learning_rate': 2.479108635097493e-05, 'epoch': 1.65}\n",
      "{'loss': 1.5376, 'learning_rate': 2.4691603660962994e-05, 'epoch': 1.66}\n",
      "{'loss': 1.5019, 'learning_rate': 2.4592120970951055e-05, 'epoch': 1.66}\n",
      "{'loss': 1.4842, 'learning_rate': 2.4492638280939118e-05, 'epoch': 1.67}\n",
      "{'loss': 1.5595, 'learning_rate': 2.439315559092718e-05, 'epoch': 1.67}\n",
      "{'loss': 1.5293, 'learning_rate': 2.429367290091524e-05, 'epoch': 1.68}\n",
      "{'loss': 1.5769, 'learning_rate': 2.41941902109033e-05, 'epoch': 1.68}\n",
      "{'loss': 1.663, 'learning_rate': 2.4094707520891365e-05, 'epoch': 1.69}\n",
      "{'loss': 1.6101, 'learning_rate': 2.399522483087943e-05, 'epoch': 1.69}\n",
      "{'loss': 1.4688, 'learning_rate': 2.3895742140867492e-05, 'epoch': 1.7}\n",
      "{'loss': 1.5246, 'learning_rate': 2.3796259450855552e-05, 'epoch': 1.7}\n",
      "{'loss': 1.461, 'learning_rate': 2.3696776760843615e-05, 'epoch': 1.71}\n",
      "{'loss': 1.4422, 'learning_rate': 2.3597294070831675e-05, 'epoch': 1.72}\n",
      "{'loss': 1.5415, 'learning_rate': 2.349781138081974e-05, 'epoch': 1.72}\n",
      "{'loss': 1.4728, 'learning_rate': 2.33983286908078e-05, 'epoch': 1.73}\n",
      "{'loss': 1.5418, 'learning_rate': 2.3298846000795862e-05, 'epoch': 1.73}\n",
      "{'loss': 1.407, 'learning_rate': 2.3199363310783926e-05, 'epoch': 1.74}\n",
      "{'loss': 1.4744, 'learning_rate': 2.309988062077199e-05, 'epoch': 1.74}\n",
      "{'loss': 1.4837, 'learning_rate': 2.300039793076005e-05, 'epoch': 1.75}\n",
      "{'loss': 1.5777, 'learning_rate': 2.290091524074811e-05, 'epoch': 1.75}\n",
      "{'loss': 1.5024, 'learning_rate': 2.2801432550736173e-05, 'epoch': 1.76}\n",
      "{'loss': 1.4609, 'learning_rate': 2.2701949860724233e-05, 'epoch': 1.76}\n",
      "{'loss': 1.5457, 'learning_rate': 2.2602467170712296e-05, 'epoch': 1.77}\n",
      "{'loss': 1.5701, 'learning_rate': 2.250298448070036e-05, 'epoch': 1.78}\n",
      "{'loss': 1.5796, 'learning_rate': 2.2403501790688423e-05, 'epoch': 1.78}\n",
      "{'loss': 1.429, 'learning_rate': 2.2304019100676483e-05, 'epoch': 1.79}\n",
      "{'loss': 1.4158, 'learning_rate': 2.2204536410664543e-05, 'epoch': 1.79}\n",
      "{'loss': 1.5722, 'learning_rate': 2.2105053720652607e-05, 'epoch': 1.8}\n",
      "{'loss': 1.6435, 'learning_rate': 2.200557103064067e-05, 'epoch': 1.8}\n",
      "{'loss': 1.4354, 'learning_rate': 2.190608834062873e-05, 'epoch': 1.81}\n",
      "{'loss': 1.411, 'learning_rate': 2.1806605650616794e-05, 'epoch': 1.81}\n",
      "{'loss': 1.5833, 'learning_rate': 2.1707122960604857e-05, 'epoch': 1.82}\n",
      "{'loss': 1.7134, 'learning_rate': 2.1607640270592917e-05, 'epoch': 1.82}\n",
      "{'loss': 1.4993, 'learning_rate': 2.1508157580580977e-05, 'epoch': 1.83}\n",
      "{'loss': 1.5192, 'learning_rate': 2.140867489056904e-05, 'epoch': 1.83}\n",
      "{'loss': 1.4667, 'learning_rate': 2.1309192200557104e-05, 'epoch': 1.84}\n",
      "{'loss': 1.4586, 'learning_rate': 2.1209709510545168e-05, 'epoch': 1.85}\n",
      "{'loss': 1.4866, 'learning_rate': 2.1110226820533228e-05, 'epoch': 1.85}\n",
      "{'loss': 1.5624, 'learning_rate': 2.101074413052129e-05, 'epoch': 1.86}\n",
      "{'loss': 1.5, 'learning_rate': 2.091126144050935e-05, 'epoch': 1.86}\n",
      "{'loss': 1.5482, 'learning_rate': 2.0811778750497415e-05, 'epoch': 1.87}\n",
      "{'loss': 1.5477, 'learning_rate': 2.0712296060485475e-05, 'epoch': 1.87}\n",
      "{'loss': 1.524, 'learning_rate': 2.0612813370473538e-05, 'epoch': 1.88}\n",
      "{'loss': 1.483, 'learning_rate': 2.0513330680461602e-05, 'epoch': 1.88}\n",
      "{'loss': 1.6469, 'learning_rate': 2.0413847990449665e-05, 'epoch': 1.89}\n",
      "{'loss': 1.5498, 'learning_rate': 2.0314365300437725e-05, 'epoch': 1.89}\n",
      "{'loss': 1.5161, 'learning_rate': 2.0214882610425785e-05, 'epoch': 1.9}\n",
      "{'loss': 1.4784, 'learning_rate': 2.011539992041385e-05, 'epoch': 1.91}\n",
      "{'loss': 1.5552, 'learning_rate': 2.0015917230401912e-05, 'epoch': 1.91}\n",
      "{'loss': 1.4759, 'learning_rate': 1.9916434540389972e-05, 'epoch': 1.92}\n",
      "{'loss': 1.3869, 'learning_rate': 1.9816951850378036e-05, 'epoch': 1.92}\n",
      "{'loss': 1.53, 'learning_rate': 1.97174691603661e-05, 'epoch': 1.93}\n",
      "{'loss': 1.4699, 'learning_rate': 1.961798647035416e-05, 'epoch': 1.93}\n",
      "{'loss': 1.4459, 'learning_rate': 1.951850378034222e-05, 'epoch': 1.94}\n",
      "{'loss': 1.4137, 'learning_rate': 1.9419021090330283e-05, 'epoch': 1.94}\n",
      "{'loss': 1.5465, 'learning_rate': 1.9319538400318346e-05, 'epoch': 1.95}\n",
      "{'loss': 1.4985, 'learning_rate': 1.922005571030641e-05, 'epoch': 1.95}\n",
      "{'loss': 1.6009, 'learning_rate': 1.912057302029447e-05, 'epoch': 1.96}\n",
      "{'loss': 1.4777, 'learning_rate': 1.9021090330282533e-05, 'epoch': 1.97}\n",
      "{'loss': 1.4698, 'learning_rate': 1.8921607640270593e-05, 'epoch': 1.97}\n",
      "{'loss': 1.3934, 'learning_rate': 1.8822124950258657e-05, 'epoch': 1.98}\n",
      "{'loss': 1.5836, 'learning_rate': 1.8722642260246717e-05, 'epoch': 1.98}\n",
      "{'loss': 1.3994, 'learning_rate': 1.862315957023478e-05, 'epoch': 1.99}\n",
      "{'loss': 1.4913, 'learning_rate': 1.8523676880222844e-05, 'epoch': 1.99}\n",
      "{'loss': 1.4037, 'learning_rate': 1.8424194190210907e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b3e8ffb039434fa6e16ac1b4f13063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5237668752670288, 'eval_runtime': 5.2887, 'eval_samples_per_second': 154.669, 'eval_steps_per_second': 19.475, 'epoch': 2.0}\n",
      "{'loss': 1.4001, 'learning_rate': 1.8324711500198967e-05, 'epoch': 2.0}\n",
      "{'loss': 1.2514, 'learning_rate': 1.8225228810187027e-05, 'epoch': 2.01}\n",
      "{'loss': 1.3985, 'learning_rate': 1.812574612017509e-05, 'epoch': 2.01}\n",
      "{'loss': 1.3864, 'learning_rate': 1.802626343016315e-05, 'epoch': 2.02}\n",
      "{'loss': 1.2959, 'learning_rate': 1.7926780740151214e-05, 'epoch': 2.02}\n",
      "{'loss': 1.2653, 'learning_rate': 1.7827298050139278e-05, 'epoch': 2.03}\n",
      "{'loss': 1.4021, 'learning_rate': 1.772781536012734e-05, 'epoch': 2.04}\n",
      "{'loss': 1.2711, 'learning_rate': 1.76283326701154e-05, 'epoch': 2.04}\n",
      "{'loss': 1.2716, 'learning_rate': 1.752884998010346e-05, 'epoch': 2.05}\n",
      "{'loss': 1.3304, 'learning_rate': 1.7429367290091525e-05, 'epoch': 2.05}\n",
      "{'loss': 1.2896, 'learning_rate': 1.7329884600079588e-05, 'epoch': 2.06}\n",
      "{'loss': 1.3458, 'learning_rate': 1.7230401910067648e-05, 'epoch': 2.06}\n",
      "{'loss': 1.3209, 'learning_rate': 1.713091922005571e-05, 'epoch': 2.07}\n",
      "{'loss': 1.221, 'learning_rate': 1.7031436530043775e-05, 'epoch': 2.07}\n",
      "{'loss': 1.3095, 'learning_rate': 1.6931953840031835e-05, 'epoch': 2.08}\n",
      "{'loss': 1.2849, 'learning_rate': 1.6832471150019895e-05, 'epoch': 2.08}\n",
      "{'loss': 1.321, 'learning_rate': 1.673298846000796e-05, 'epoch': 2.09}\n",
      "{'loss': 1.3041, 'learning_rate': 1.6633505769996022e-05, 'epoch': 2.1}\n",
      "{'loss': 1.2738, 'learning_rate': 1.6534023079984085e-05, 'epoch': 2.1}\n",
      "{'loss': 1.3072, 'learning_rate': 1.6434540389972145e-05, 'epoch': 2.11}\n",
      "{'loss': 1.3663, 'learning_rate': 1.633505769996021e-05, 'epoch': 2.11}\n",
      "{'loss': 1.334, 'learning_rate': 1.623557500994827e-05, 'epoch': 2.12}\n",
      "{'loss': 1.2873, 'learning_rate': 1.6136092319936332e-05, 'epoch': 2.12}\n",
      "{'loss': 1.3015, 'learning_rate': 1.6036609629924392e-05, 'epoch': 2.13}\n",
      "{'loss': 1.3991, 'learning_rate': 1.5937126939912456e-05, 'epoch': 2.13}\n",
      "{'loss': 1.3066, 'learning_rate': 1.583764424990052e-05, 'epoch': 2.14}\n",
      "{'loss': 1.4151, 'learning_rate': 1.5738161559888583e-05, 'epoch': 2.14}\n",
      "{'loss': 1.2746, 'learning_rate': 1.5638678869876643e-05, 'epoch': 2.15}\n",
      "{'loss': 1.4082, 'learning_rate': 1.5539196179864703e-05, 'epoch': 2.16}\n",
      "{'loss': 1.2947, 'learning_rate': 1.5439713489852766e-05, 'epoch': 2.16}\n",
      "{'loss': 1.3927, 'learning_rate': 1.534023079984083e-05, 'epoch': 2.17}\n",
      "{'loss': 1.2518, 'learning_rate': 1.524074810982889e-05, 'epoch': 2.17}\n",
      "{'loss': 1.3116, 'learning_rate': 1.5141265419816952e-05, 'epoch': 2.18}\n",
      "{'loss': 1.3903, 'learning_rate': 1.5041782729805015e-05, 'epoch': 2.18}\n",
      "{'loss': 1.2321, 'learning_rate': 1.4942300039793079e-05, 'epoch': 2.19}\n",
      "{'loss': 1.2157, 'learning_rate': 1.4842817349781139e-05, 'epoch': 2.19}\n",
      "{'loss': 1.3112, 'learning_rate': 1.47433346597692e-05, 'epoch': 2.2}\n",
      "{'loss': 1.2632, 'learning_rate': 1.4643851969757264e-05, 'epoch': 2.2}\n",
      "{'loss': 1.3514, 'learning_rate': 1.4544369279745326e-05, 'epoch': 2.21}\n",
      "{'loss': 1.3625, 'learning_rate': 1.4444886589733386e-05, 'epoch': 2.21}\n",
      "{'loss': 1.4102, 'learning_rate': 1.4345403899721449e-05, 'epoch': 2.22}\n",
      "{'loss': 1.2653, 'learning_rate': 1.4245921209709513e-05, 'epoch': 2.23}\n",
      "{'loss': 1.2172, 'learning_rate': 1.4146438519697574e-05, 'epoch': 2.23}\n",
      "{'loss': 1.2956, 'learning_rate': 1.4046955829685634e-05, 'epoch': 2.24}\n",
      "{'loss': 1.301, 'learning_rate': 1.3947473139673698e-05, 'epoch': 2.24}\n",
      "{'loss': 1.2434, 'learning_rate': 1.384799044966176e-05, 'epoch': 2.25}\n",
      "{'loss': 1.249, 'learning_rate': 1.3748507759649823e-05, 'epoch': 2.25}\n",
      "{'loss': 1.2862, 'learning_rate': 1.3649025069637883e-05, 'epoch': 2.26}\n",
      "{'loss': 1.324, 'learning_rate': 1.355949064862714e-05, 'epoch': 2.26}\n",
      "{'loss': 1.2819, 'learning_rate': 1.34600079586152e-05, 'epoch': 2.27}\n",
      "{'loss': 1.1904, 'learning_rate': 1.3360525268603264e-05, 'epoch': 2.27}\n",
      "{'loss': 1.2649, 'learning_rate': 1.3261042578591325e-05, 'epoch': 2.28}\n",
      "{'loss': 1.398, 'learning_rate': 1.3161559888579389e-05, 'epoch': 2.29}\n",
      "{'loss': 1.2216, 'learning_rate': 1.3062077198567449e-05, 'epoch': 2.29}\n",
      "{'loss': 1.2912, 'learning_rate': 1.2962594508555512e-05, 'epoch': 2.3}\n",
      "{'loss': 1.2232, 'learning_rate': 1.2863111818543574e-05, 'epoch': 2.3}\n",
      "{'loss': 1.2503, 'learning_rate': 1.2763629128531638e-05, 'epoch': 2.31}\n",
      "{'loss': 1.2561, 'learning_rate': 1.2664146438519698e-05, 'epoch': 2.31}\n",
      "{'loss': 1.4365, 'learning_rate': 1.256466374850776e-05, 'epoch': 2.32}\n",
      "{'loss': 1.3497, 'learning_rate': 1.2465181058495823e-05, 'epoch': 2.32}\n",
      "{'loss': 1.3516, 'learning_rate': 1.2365698368483885e-05, 'epoch': 2.33}\n",
      "{'loss': 1.4127, 'learning_rate': 1.2266215678471946e-05, 'epoch': 2.33}\n",
      "{'loss': 1.3527, 'learning_rate': 1.2166732988460008e-05, 'epoch': 2.34}\n",
      "{'loss': 1.2781, 'learning_rate': 1.2067250298448072e-05, 'epoch': 2.35}\n",
      "{'loss': 1.2787, 'learning_rate': 1.1967767608436133e-05, 'epoch': 2.35}\n",
      "{'loss': 1.2102, 'learning_rate': 1.1868284918424195e-05, 'epoch': 2.36}\n",
      "{'loss': 1.2397, 'learning_rate': 1.1768802228412257e-05, 'epoch': 2.36}\n",
      "{'loss': 1.2853, 'learning_rate': 1.166931953840032e-05, 'epoch': 2.37}\n",
      "{'loss': 1.3197, 'learning_rate': 1.156983684838838e-05, 'epoch': 2.37}\n",
      "{'loss': 1.4251, 'learning_rate': 1.1470354158376444e-05, 'epoch': 2.38}\n",
      "{'loss': 1.2984, 'learning_rate': 1.1370871468364505e-05, 'epoch': 2.38}\n",
      "{'loss': 1.2534, 'learning_rate': 1.1271388778352567e-05, 'epoch': 2.39}\n",
      "{'loss': 1.3061, 'learning_rate': 1.1171906088340629e-05, 'epoch': 2.39}\n",
      "{'loss': 1.2908, 'learning_rate': 1.107242339832869e-05, 'epoch': 2.4}\n",
      "{'loss': 1.3216, 'learning_rate': 1.0972940708316754e-05, 'epoch': 2.4}\n",
      "{'loss': 1.2647, 'learning_rate': 1.0873458018304814e-05, 'epoch': 2.41}\n",
      "{'loss': 1.2567, 'learning_rate': 1.0773975328292878e-05, 'epoch': 2.42}\n",
      "{'loss': 1.2648, 'learning_rate': 1.067449263828094e-05, 'epoch': 2.42}\n",
      "{'loss': 1.3458, 'learning_rate': 1.0575009948269001e-05, 'epoch': 2.43}\n",
      "{'loss': 1.3094, 'learning_rate': 1.0475527258257063e-05, 'epoch': 2.43}\n",
      "{'loss': 1.2979, 'learning_rate': 1.0376044568245126e-05, 'epoch': 2.44}\n",
      "{'loss': 1.3593, 'learning_rate': 1.0276561878233188e-05, 'epoch': 2.44}\n",
      "{'loss': 1.364, 'learning_rate': 1.017707918822125e-05, 'epoch': 2.45}\n",
      "{'loss': 1.2711, 'learning_rate': 1.0077596498209312e-05, 'epoch': 2.45}\n",
      "{'loss': 1.3079, 'learning_rate': 9.978113808197375e-06, 'epoch': 2.46}\n",
      "{'loss': 1.4169, 'learning_rate': 9.878631118185435e-06, 'epoch': 2.46}\n",
      "{'loss': 1.4271, 'learning_rate': 9.779148428173499e-06, 'epoch': 2.47}\n",
      "{'loss': 1.2602, 'learning_rate': 9.67966573816156e-06, 'epoch': 2.48}\n",
      "{'loss': 1.3333, 'learning_rate': 9.590131317150816e-06, 'epoch': 2.48}\n",
      "{'loss': 1.3012, 'learning_rate': 9.49064862713888e-06, 'epoch': 2.49}\n",
      "{'loss': 1.3809, 'learning_rate': 9.391165937126941e-06, 'epoch': 2.49}\n",
      "{'loss': 1.2314, 'learning_rate': 9.291683247115003e-06, 'epoch': 2.5}\n",
      "{'loss': 1.3066, 'learning_rate': 9.192200557103064e-06, 'epoch': 2.5}\n",
      "{'loss': 1.4261, 'learning_rate': 9.092717867091128e-06, 'epoch': 2.51}\n",
      "{'loss': 1.2156, 'learning_rate': 8.993235177079188e-06, 'epoch': 2.51}\n",
      "{'loss': 1.2253, 'learning_rate': 8.89375248706725e-06, 'epoch': 2.52}\n",
      "{'loss': 1.3301, 'learning_rate': 8.794269797055313e-06, 'epoch': 2.52}\n",
      "{'loss': 1.2084, 'learning_rate': 8.694787107043375e-06, 'epoch': 2.53}\n",
      "{'loss': 1.3154, 'learning_rate': 8.595304417031437e-06, 'epoch': 2.54}\n",
      "{'loss': 1.2788, 'learning_rate': 8.495821727019498e-06, 'epoch': 2.54}\n",
      "{'loss': 1.2562, 'learning_rate': 8.396339037007562e-06, 'epoch': 2.55}\n",
      "{'loss': 1.2768, 'learning_rate': 8.296856346995622e-06, 'epoch': 2.55}\n",
      "{'loss': 1.3726, 'learning_rate': 8.197373656983685e-06, 'epoch': 2.56}\n",
      "{'loss': 1.3388, 'learning_rate': 8.097890966971747e-06, 'epoch': 2.56}\n",
      "{'loss': 1.2828, 'learning_rate': 7.998408276959809e-06, 'epoch': 2.57}\n",
      "{'loss': 1.3555, 'learning_rate': 7.89892558694787e-06, 'epoch': 2.57}\n",
      "{'loss': 1.386, 'learning_rate': 7.799442896935934e-06, 'epoch': 2.58}\n",
      "{'loss': 1.2555, 'learning_rate': 7.699960206923996e-06, 'epoch': 2.58}\n",
      "{'loss': 1.3169, 'learning_rate': 7.600477516912058e-06, 'epoch': 2.59}\n",
      "{'loss': 1.2264, 'learning_rate': 7.500994826900119e-06, 'epoch': 2.6}\n",
      "{'loss': 1.3499, 'learning_rate': 7.401512136888182e-06, 'epoch': 2.6}\n",
      "{'loss': 1.3154, 'learning_rate': 7.302029446876244e-06, 'epoch': 2.61}\n",
      "{'loss': 1.2907, 'learning_rate': 7.202546756864306e-06, 'epoch': 2.61}\n",
      "{'loss': 1.2559, 'learning_rate': 7.103064066852367e-06, 'epoch': 2.62}\n",
      "{'loss': 1.2252, 'learning_rate': 7.003581376840431e-06, 'epoch': 2.62}\n",
      "{'loss': 1.3627, 'learning_rate': 6.904098686828492e-06, 'epoch': 2.63}\n",
      "{'loss': 1.2776, 'learning_rate': 6.804615996816554e-06, 'epoch': 2.63}\n",
      "{'loss': 1.3118, 'learning_rate': 6.705133306804616e-06, 'epoch': 2.64}\n",
      "{'loss': 1.2733, 'learning_rate': 6.6056506167926786e-06, 'epoch': 2.64}\n",
      "{'loss': 1.3993, 'learning_rate': 6.50616792678074e-06, 'epoch': 2.65}\n",
      "{'loss': 1.2457, 'learning_rate': 6.406685236768803e-06, 'epoch': 2.65}\n",
      "{'loss': 1.3783, 'learning_rate': 6.307202546756865e-06, 'epoch': 2.66}\n",
      "{'loss': 1.2493, 'learning_rate': 6.207719856744926e-06, 'epoch': 2.67}\n",
      "{'loss': 1.3221, 'learning_rate': 6.108237166732988e-06, 'epoch': 2.67}\n",
      "{'loss': 1.3894, 'learning_rate': 6.008754476721051e-06, 'epoch': 2.68}\n",
      "{'loss': 1.2609, 'learning_rate': 5.9092717867091125e-06, 'epoch': 2.68}\n",
      "{'loss': 1.1658, 'learning_rate': 5.809789096697175e-06, 'epoch': 2.69}\n",
      "{'loss': 1.2598, 'learning_rate': 5.710306406685237e-06, 'epoch': 2.69}\n",
      "{'loss': 1.2963, 'learning_rate': 5.610823716673299e-06, 'epoch': 2.7}\n",
      "{'loss': 1.2479, 'learning_rate': 5.511341026661361e-06, 'epoch': 2.7}\n",
      "{'loss': 1.2956, 'learning_rate': 5.411858336649423e-06, 'epoch': 2.71}\n",
      "{'loss': 1.2765, 'learning_rate': 5.312375646637486e-06, 'epoch': 2.71}\n",
      "{'loss': 1.1347, 'learning_rate': 5.212892956625547e-06, 'epoch': 2.72}\n",
      "{'loss': 1.2124, 'learning_rate': 5.113410266613609e-06, 'epoch': 2.73}\n",
      "{'loss': 1.2985, 'learning_rate': 5.013927576601672e-06, 'epoch': 2.73}\n",
      "{'loss': 1.3381, 'learning_rate': 4.9144448865897334e-06, 'epoch': 2.74}\n",
      "{'loss': 1.3179, 'learning_rate': 4.814962196577796e-06, 'epoch': 2.74}\n",
      "{'loss': 1.3315, 'learning_rate': 4.715479506565858e-06, 'epoch': 2.75}\n",
      "{'loss': 1.2905, 'learning_rate': 4.6159968165539196e-06, 'epoch': 2.75}\n",
      "{'loss': 1.2522, 'learning_rate': 4.516514126541982e-06, 'epoch': 2.76}\n",
      "{'loss': 1.199, 'learning_rate': 4.417031436530044e-06, 'epoch': 2.76}\n",
      "{'loss': 1.3217, 'learning_rate': 4.3175487465181065e-06, 'epoch': 2.77}\n",
      "{'loss': 1.3149, 'learning_rate': 4.218066056506168e-06, 'epoch': 2.77}\n",
      "{'loss': 1.3678, 'learning_rate': 4.11858336649423e-06, 'epoch': 2.78}\n",
      "{'loss': 1.2541, 'learning_rate': 4.019100676482293e-06, 'epoch': 2.79}\n",
      "{'loss': 1.2686, 'learning_rate': 3.919617986470354e-06, 'epoch': 2.79}\n",
      "{'loss': 1.3381, 'learning_rate': 3.820135296458416e-06, 'epoch': 2.8}\n",
      "{'loss': 1.1933, 'learning_rate': 3.7206526064464787e-06, 'epoch': 2.8}\n",
      "{'loss': 1.3099, 'learning_rate': 3.621169916434541e-06, 'epoch': 2.81}\n",
      "{'loss': 1.2328, 'learning_rate': 3.5216872264226027e-06, 'epoch': 2.81}\n",
      "{'loss': 1.2384, 'learning_rate': 3.422204536410665e-06, 'epoch': 2.82}\n",
      "{'loss': 1.2503, 'learning_rate': 3.322721846398727e-06, 'epoch': 2.82}\n",
      "{'loss': 1.2466, 'learning_rate': 3.223239156386789e-06, 'epoch': 2.83}\n",
      "{'loss': 1.4422, 'learning_rate': 3.123756466374851e-06, 'epoch': 2.83}\n",
      "{'loss': 1.293, 'learning_rate': 3.0242737763629127e-06, 'epoch': 2.84}\n",
      "{'loss': 1.2085, 'learning_rate': 2.924791086350975e-06, 'epoch': 2.84}\n",
      "{'loss': 1.2502, 'learning_rate': 2.825308396339037e-06, 'epoch': 2.85}\n",
      "{'loss': 1.2876, 'learning_rate': 2.7258257063270992e-06, 'epoch': 2.86}\n",
      "{'loss': 1.2545, 'learning_rate': 2.6263430163151614e-06, 'epoch': 2.86}\n",
      "{'loss': 1.2757, 'learning_rate': 2.526860326303223e-06, 'epoch': 2.87}\n",
      "{'loss': 1.326, 'learning_rate': 2.4273776362912853e-06, 'epoch': 2.87}\n",
      "{'loss': 1.339, 'learning_rate': 2.3278949462793475e-06, 'epoch': 2.88}\n",
      "{'loss': 1.269, 'learning_rate': 2.2284122562674097e-06, 'epoch': 2.88}\n",
      "{'loss': 1.2804, 'learning_rate': 2.128929566255472e-06, 'epoch': 2.89}\n",
      "{'loss': 1.316, 'learning_rate': 2.0294468762435336e-06, 'epoch': 2.89}\n",
      "{'loss': 1.3496, 'learning_rate': 1.929964186231596e-06, 'epoch': 2.9}\n",
      "{'loss': 1.1604, 'learning_rate': 1.830481496219658e-06, 'epoch': 2.9}\n",
      "{'loss': 1.3667, 'learning_rate': 1.73099880620772e-06, 'epoch': 2.91}\n",
      "{'loss': 1.3415, 'learning_rate': 1.6315161161957821e-06, 'epoch': 2.92}\n",
      "{'loss': 1.193, 'learning_rate': 1.532033426183844e-06, 'epoch': 2.92}\n",
      "{'loss': 1.3729, 'learning_rate': 1.432550736171906e-06, 'epoch': 2.93}\n",
      "{'loss': 1.3505, 'learning_rate': 1.3330680461599682e-06, 'epoch': 2.93}\n",
      "{'loss': 1.3623, 'learning_rate': 1.2335853561480302e-06, 'epoch': 2.94}\n",
      "{'loss': 1.2216, 'learning_rate': 1.1341026661360924e-06, 'epoch': 2.94}\n",
      "{'loss': 1.3543, 'learning_rate': 1.0346199761241545e-06, 'epoch': 2.95}\n",
      "{'loss': 1.28, 'learning_rate': 9.351372861122165e-07, 'epoch': 2.95}\n",
      "{'loss': 1.2522, 'learning_rate': 8.356545961002787e-07, 'epoch': 2.96}\n",
      "{'loss': 1.2972, 'learning_rate': 7.361719060883407e-07, 'epoch': 2.96}\n",
      "{'loss': 1.2641, 'learning_rate': 6.366892160764027e-07, 'epoch': 2.97}\n",
      "{'loss': 1.3272, 'learning_rate': 5.372065260644648e-07, 'epoch': 2.98}\n",
      "{'loss': 1.3004, 'learning_rate': 4.377238360525269e-07, 'epoch': 2.98}\n",
      "{'loss': 1.3319, 'learning_rate': 3.3824114604058894e-07, 'epoch': 2.99}\n",
      "{'loss': 1.3292, 'learning_rate': 2.38758456028651e-07, 'epoch': 2.99}\n",
      "{'loss': 1.2903, 'learning_rate': 1.392757660167131e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2091f3eb054b47838f2be2ef978eb661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5043226480484009, 'eval_runtime': 4.9871, 'eval_samples_per_second': 164.025, 'eval_steps_per_second': 20.653, 'epoch': 3.0}\n",
      "{'train_runtime': 950.3244, 'train_samples_per_second': 46.506, 'train_steps_per_second': 5.815, 'train_loss': 1.6018858128512117, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5526, training_loss=1.6018858128512117, metrics={'train_runtime': 950.3244, 'train_samples_per_second': 46.506, 'train_steps_per_second': 5.815, 'train_loss': 1.6018858128512117, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save_pretrained(\"../models/samsum_bart_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the data left on the gpu\n",
    "model = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelfinetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
